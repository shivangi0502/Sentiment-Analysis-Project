{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7dac859",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71869a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03 Notebook Current working directory: c:\\Users\\asus\\OneDrive\\Desktop\\projects\\sentiment_analysis_project\\notebook\n",
      "03 Notebook Calculated project root: c:\\Users\\asus\\OneDrive\\Desktop\\projects\\sentiment_analysis_project\n",
      "03 Notebook Added project root to sys.path: c:\\Users\\asus\\OneDrive\\Desktop\\projects\\sentiment_analysis_project\n",
      "03 Notebook Calculated data directory: c:\\Users\\asus\\OneDrive\\Desktop\\projects\\sentiment_analysis_project\\data\n",
      "Data directory already exists: c:\\Users\\asus\\OneDrive\\Desktop\\projects\\sentiment_analysis_project\\data\n"
     ]
    }
   ],
   "source": [
    "\n",
    "current_dir = os.getcwd()\n",
    "print(f\"03 Notebook Current working directory: {current_dir}\") # DEBUG\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(current_dir, '..'))\n",
    "print(f\"03 Notebook Calculated project root: {project_root}\") # DEBUG\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "    print(f\"03 Notebook Added project root to sys.path: {project_root}\") # DEBUG\n",
    "\n",
    "data_dir = os.path.join(project_root, 'data')\n",
    "print(f\"03 Notebook Calculated data directory: {data_dir}\") # DEBUG\n",
    "\n",
    "\n",
    "if not os.path.exists(data_dir):\n",
    "    try:\n",
    "        os.makedirs(data_dir)\n",
    "        print(f\"Successfully created directory: {data_dir}\")\n",
    "    except OSError as e:\n",
    "        print(f\"ERROR: Failed to create data directory {data_dir}. Reason: {e}\")\n",
    "        # Consider raising the error if it's critical to stop here\n",
    "else:\n",
    "    print(f\"Data directory already exists: {data_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1911549e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03 Notebook Attempting to load data from: c:\\Users\\asus\\OneDrive\\Desktop\\projects\\sentiment_analysis_project\\data\\tweet_eval_sentiment_multiclass_preprocessed.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_19884\\2003256488.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['processed_text'].fillna('', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Load preprocessed data \n",
    "file_to_load = os.path.join(data_dir, 'tweet_eval_sentiment_multiclass_preprocessed.csv')\n",
    "\n",
    "print(f\"03 Notebook Attempting to load data from: {file_to_load}\")\n",
    "if not os.path.exists(file_to_load):\n",
    "    print(f\"ERROR: File does not exist at {file_to_load}.\")\n",
    "    raise FileNotFoundError(f\"Missing preprocessed data file: {file_to_load}\")\n",
    "\n",
    "df = pd.read_csv(file_to_load)\n",
    "\n",
    "df['processed_text'].fillna('', inplace=True)\n",
    "df['processed_text'] = df['processed_text'].astype(str)\n",
    "df = df[df['processed_text'].str.strip() != ''].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee27f89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1000 samples for Hugging Face pipeline evaluation.\n"
     ]
    }
   ],
   "source": [
    "sample_df = df.sample(n=1000, random_state=42).copy()\n",
    "print(f\"Using {len(sample_df)} samples for Hugging Face pipeline evaluation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5a8be23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using hugging face model: cardiffnlp/twitter-roberta-base-sentiment\n"
     ]
    }
   ],
   "source": [
    "X_sample = sample_df['text'] \n",
    "y_sample = sample_df['sentiment']\n",
    "hf_model_name = 'cardiffnlp/twitter-roberta-base-sentiment'\n",
    "classifier = pipeline('sentiment-analysis', model=hf_model_name)\n",
    "print(f\"using hugging face model: {hf_model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04ca219e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc841b1eaacd40b88db4e59c10469fe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "predicting with hugging face pipeline:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hf_predictions = []\n",
    "for text in tqdm(X_sample, desc=\"predicting with hugging face pipeline\"):\n",
    "    result = classifier(text)[0]\n",
    "    predicted_label = result['label']\n",
    "    \n",
    "    label_map = {'LABEL_0':0, 'LABEL_1':1, 'LABEL_2': 2}\n",
    "    hf_predictions.append(label_map.get(predicted_label, -1))\n",
    "hf_raw_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97737095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73ee4f560e6c4bc299162c90f85bc1e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting with Hugging Face Pipeline:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "for text in tqdm(X_sample, desc=\"Predicting with Hugging Face Pipeline\"):\n",
    "    \n",
    "    result = classifier(text)\n",
    "    hf_raw_results.append(result[0])\n",
    "    predicted_label_text = result[0]['label']\n",
    "\n",
    "    \n",
    "    if predicted_label_text.upper() == 'NEGATIVE':\n",
    "        hf_predictions.append(0)\n",
    "    elif predicted_label_text.upper() == 'POSITIVE':\n",
    "        hf_predictions.append(1)\n",
    "    else:\n",
    "        \n",
    "        hf_predictions.append(-1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9be458ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered out 0 samples due to unmappable HF predictions.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Filter out any unmappable predictions if they occurred\n",
    "if -1 in hf_predictions:\n",
    "    initial_len = len(y_sample)\n",
    "    valid_indices = [i for i, pred in enumerate(hf_predictions) if pred != -1]\n",
    "    y_sample = y_sample.iloc[valid_indices]\n",
    "    hf_predictions = [hf_predictions[i] for i in valid_indices]\n",
    "    print(f\"Filtered out {initial_len - len(y_sample)} samples due to unmappable HF predictions.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4882dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ensure lengths match before evaluation (after filtering)\n",
    "if len(y_sample) != len(hf_predictions):\n",
    "    print(f\"Warning: Length mismatch. y_sample: {len(y_sample)}, hf_predictions: {len(hf_predictions)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe77b37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Evaluation for Hugging Face Pipeline ---\n",
      "Accuracy: 0.8140\n",
      "Precision: 0.8166\n",
      "Recall: 0.8140\n",
      "F1-Score: 0.8141\n",
      "\n",
      "Classification Report (Hugging Face):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.79      0.81      0.80       194\n",
      "     Neutral       0.79      0.84      0.82       478\n",
      "    Positive       0.87      0.78      0.82       328\n",
      "\n",
      "    accuracy                           0.81      1000\n",
      "   macro avg       0.82      0.81      0.81      1000\n",
      "weighted avg       0.82      0.81      0.81      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Hugging Face pipeline\n",
    "print(\"\\n--- Evaluation for Hugging Face Pipeline ---\")\n",
    "print(f\"Accuracy: {accuracy_score(y_sample, hf_predictions):.4f}\")\n",
    "\n",
    "print(f\"Precision: {precision_score(y_sample, hf_predictions, average='weighted', zero_division=0):.4f}\")\n",
    "print(f\"Recall: {recall_score(y_sample, hf_predictions, average='weighted', zero_division=0):.4f}\")\n",
    "print(f\"F1-Score: {f1_score(y_sample, hf_predictions, average='weighted', zero_division=0):.4f}\")\n",
    "print(\"\\nClassification Report (Hugging Face):\")\n",
    "\n",
    "print(classification_report(y_sample, hf_predictions, target_names=['Negative', 'Neutral', 'Positive'], zero_division=0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c22d3757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face evaluation data saved for app.py\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "models_dir = os.path.join(project_root, 'models')\n",
    "\n",
    "hf_eval_data={\n",
    "    'y_pred': hf_predictions,\n",
    "    'y_true': y_sample\n",
    "}\n",
    "\n",
    "with open (os.path.join(models_dir, 'hf_eval_data.pkl'), 'wb') as f:\n",
    "    pickle.dump(hf_eval_data, f)\n",
    "print(\"Hugging Face evaluation data saved for app.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd252361",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentiment_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
